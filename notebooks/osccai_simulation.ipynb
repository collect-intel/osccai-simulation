{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iQNaVxpuhubY"
      },
      "source": [
        "# OSCCAI Simulation Notebook\n",
        "\n",
        "## Usage Instructions\n",
        "\n",
        "This notebook simulates output from an Open Source Collective Constitutional AI (OSCCAI) tool.\n",
        "You will need an OpenAI API key to run this notebook. Set it as an environment variable or enter it when prompted.\n",
        "\n",
        "If running in Google Colab: this should already work with the notebook, but if not you can add your own `OPENAI_API_KEY` as a Secret on the left menubar.\n",
        "\n",
        "**Running:** Select **Runtime** > **Run all**. Step #4: *User Input Collection* will prompt you for input about the community if the `USE_DEFAULT_COMMUNITY` flag below is set to `False`. Otherwise, the notebook will run through using a default community input.\n",
        "\n",
        "**LLM Caching:**\n",
        "This notebook makes use of caching to save on API usage when running the same API requests multiple times. Running this notebook through to the end will save an llm_cache file locally. You can upload this file from a previous session when prompted to restore this cache.\n",
        "\n",
        "**Required Setup:**\n",
        "- Set your OpenAI API key:\n",
        "  - Option 1: Set as an environment variable or Google Colab Secret `OPENAI_API_KEY`\n",
        "  - Option 2: Enter it when prompted in the notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGJLhLbuf5rB"
      },
      "outputs": [],
      "source": [
        "# Define flags to control whether to use default inputs to see this run without requiring input\n",
        "USE_DEFAULT_DATA = True\n",
        "USE_DEFAULT_COMMUNITY = True\n",
        "\n",
        "# Default values used when USE_DEFAULT_COMMUNITY = True\n",
        "DEFAULT_NUM_SUBGROUPS = 3\n",
        "DEFAULT_NUM_PARTICIPANTS = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6jFAI_zhuba"
      },
      "source": [
        "## 1. Setup and Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nRJaa8GZhubb"
      },
      "outputs": [],
      "source": [
        "# Uncomment and run this cell to install required packages\n",
        "!pip install numpy pandas matplotlib openai tenacity asyncio nest_asyncio kneed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IITX634Chubb"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "from getpass import getpass\n",
        "from IPython.display import display, Markdown\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.stats import beta, nbinom\n",
        "import random\n",
        "from openai import OpenAI\n",
        "import openai\n",
        "\n",
        "# Try to import from google.colab if available, otherwise use a fallback\n",
        "try:\n",
        "    from google.colab import files, userdata\n",
        "    IN_COLAB = True\n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "\n",
        "    # Fallback function for file upload in Jupyter Notebook\n",
        "    def upload_files():\n",
        "        from ipywidgets import FileUpload\n",
        "        from IPython.display import display\n",
        "\n",
        "        uploader = FileUpload(accept='.csv', multiple=False)\n",
        "        display(uploader)\n",
        "\n",
        "        def on_upload_change(change):\n",
        "            if change['type'] == 'change' and change['name'] == 'value':\n",
        "                filename = list(change['new'].keys())[0]\n",
        "                content = change['new'][filename]['content']\n",
        "                with open(filename, 'wb') as f:\n",
        "                    f.write(content)\n",
        "                print(f\"Uploaded file: {filename}\")\n",
        "\n",
        "        uploader.observe(on_upload_change, names='value')\n",
        "        return uploader\n",
        "\n",
        "# Set up OpenAI API key\n",
        "if os.getenv(\"OPENAI_API_KEY\"):\n",
        "    client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
        "elif IN_COLAB and userdata.get('OPENAI_API_KEY'):\n",
        "    # Add OPENAI_API_KEY as secret in google colab to skip manual entry\n",
        "    client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "else:\n",
        "    client = OpenAI(api_key=getpass(\"Please enter your OpenAI API key: \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXf8BMXeWJKq"
      },
      "outputs": [],
      "source": [
        "# Use cache to efficiently store and reuse LLM responses\n",
        "import hashlib\n",
        "from functools import lru_cache\n",
        "import functools\n",
        "\n",
        "# Create a cache dictionary\n",
        "llm_cache = {}\n",
        "\n",
        "# generate cache key for prompts and responses, or functions and return results\n",
        "def generate_cache_key(item, item_type='prompt', add_context=None):\n",
        "    if item_type == 'prompt':\n",
        "        key_string = f\"{item}\"\n",
        "    elif item_type == 'function':\n",
        "        func_name, args, kwargs = item\n",
        "        args_str = ','.join(map(str, args))\n",
        "        kwargs_str = ','.join(f\"{k}={v}\" for k, v in kwargs.items())\n",
        "        key_string = f\"{func_name}:{args_str}:{kwargs_str}\"\n",
        "    \n",
        "    if add_context:\n",
        "        key_string += f\":{add_context}\"\n",
        "    \n",
        "    return hashlib.md5(key_string.encode()).hexdigest()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgOUSi2Hhubc"
      },
      "source": [
        "## 2. Data Upload and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TtqRxbjhubc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "from io import StringIO\n",
        "\n",
        "# Default files if Default flag is True\n",
        "DATA_FILE_URL = \"https://raw.githubusercontent.com/collect-intel/osccai-simulation/refs/heads/main/data/ccai_polis_data_voters.csv\"\n",
        "COMMUNITY_FILE_URL = \"https://raw.githubusercontent.com/collect-intel/osccai-simulation/refs/heads/llm-simulation/data/simulation_community_inputs.json\"\n",
        "LLM_CACHE_FILE_URL = \"https://raw.githubusercontent.com/collect-intel/osccai-simulation/refs/heads/llm-simulation/data/llm_cache.json\"\n",
        "\n",
        "# Function to curl the CSV from GitHub\n",
        "def curl_github_file(url):\n",
        "    response = requests.get(url)\n",
        "    return response.text if response.status_code == 200 else None\n",
        "\n",
        "# Load baseline LLM cache\n",
        "print(\"Attempting to load baseline LLM cache from GitHub...\")\n",
        "baseline_cache_json = curl_github_file(LLM_CACHE_FILE_URL)\n",
        "if baseline_cache_json:\n",
        "    baseline_llm_cache = json.loads(baseline_cache_json)\n",
        "    print(f\"Loaded {len(baseline_llm_cache)} items into baseline LLM cache\")\n",
        "else:\n",
        "    print(\"Failed to load baseline LLM cache. Proceeding without it.\")\n",
        "    baseline_llm_cache = {}\n",
        "\n",
        "# Get actual data to base distributions on\n",
        "if USE_DEFAULT_DATA:\n",
        "    print(\"Attempting to load data from GitHub...\")\n",
        "    csv_content = curl_github_file(DATA_FILE_URL)\n",
        "    if csv_content:\n",
        "        data = pd.read_csv(StringIO(csv_content))\n",
        "    else:\n",
        "        print(\"Failed to load default data. Please upload manually.\")\n",
        "        USE_DEFAULT_DATA = False\n",
        "\n",
        "if not USE_DEFAULT_DATA:\n",
        "    print(\"Please upload your Polis data CSV file.\")\n",
        "    if IN_COLAB:\n",
        "        uploaded = files.upload()\n",
        "        filename = list(uploaded.keys())[0]\n",
        "    else:\n",
        "        uploader = upload_files()\n",
        "        # Wait for the user to upload a file\n",
        "        while not uploader.value:\n",
        "            pass\n",
        "        filename = list(uploader.value.keys())[0]\n",
        "\n",
        "    # Load the uploaded CSV into a DataFrame\n",
        "    data = pd.read_csv(filename)\n",
        "\n",
        "# Verify that data was loaded\n",
        "if data is not None:\n",
        "    print(\"Data loaded successfully.\")\n",
        "    print(f\"Shape of the data: {data.shape}\")\n",
        "else:\n",
        "    print(\"Failed to load data. Please check your input or try uploading manually.\")\n",
        "\n",
        "# Load community inputs\n",
        "if USE_DEFAULT_COMMUNITY:\n",
        "    print(\"Attempting to load community inputs from GitHub...\")\n",
        "    community_json = curl_github_file(COMMUNITY_FILE_URL)\n",
        "    if community_json:\n",
        "        community_data = json.loads(community_json)[1]\n",
        "        print(\"Community inputs loaded successfully.\")\n",
        "    else:\n",
        "        print(\"Failed to load default community inputs. Will prompt for manual input.\")\n",
        "        USE_DEFAULT_COMMUNITY = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KDDoHtLblCY_"
      },
      "outputs": [],
      "source": [
        "# Calculate additional metrics\n",
        "\n",
        "# Calculate pass votes per participant\n",
        "data['n-pass'] = data['n-votes'] - (data['n-agree'] + data['n-disagree'])\n",
        "\n",
        "# Calculate % agree, % disagree, and % pass per participant\n",
        "data['% agree'] = data['n-agree'] / data['n-votes']\n",
        "data['% disagree'] = data['n-disagree'] / data['n-votes']\n",
        "data['% pass'] = data['n-pass'] / data['n-votes']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHn6gXQ4hubc"
      },
      "source": [
        "## 3. Define Simulation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# cache results from simulation functions to make idempotent\n",
        "def cache_result(func):\n",
        "    @functools.wraps(func)\n",
        "    def wrapper(*args, **kwargs):\n",
        "        data_context = DATA_FILE_URL if USE_DEFAULT_DATA else 'custom_data'\n",
        "        cache_key = generate_cache_key((func.__name__, args, kwargs), item_type='function', add_context=data_context)\n",
        "        if cache_key in llm_cache:\n",
        "            print(f\"Using cached result for {func.__name__}\")\n",
        "            return llm_cache[cache_key]\n",
        "        result = func(*args, **kwargs)\n",
        "        llm_cache[cache_key] = result\n",
        "        return result\n",
        "    return wrapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d80ouVqnhubc"
      },
      "outputs": [],
      "source": [
        "def fit_beta_distribution(data):\n",
        "    \"\"\"Fit a beta distribution to the given data.\"\"\"\n",
        "    data_cleaned = data.clip(lower=0.001, upper=0.999)\n",
        "    a, b, _, _ = beta.fit(data_cleaned, floc=0, fscale=1)\n",
        "    return a, b\n",
        "\n",
        "def fit_negative_binomial(data):\n",
        "    \"\"\"Fit a negative binomial distribution to the given data.\"\"\"\n",
        "    mean = data.mean()\n",
        "    var = data.var()\n",
        "    n = (mean ** 2) / (var - mean) if var > mean else 10\n",
        "    p = mean / (mean + n)\n",
        "    return n, p\n",
        "\n",
        "@cache_result\n",
        "def calculate_statements_per_participant(num_participants):\n",
        "    \"\"\"Calculate the number of statements per participant based on actual data.\"\"\"\n",
        "    fattening_factor = 3 # fatten the right tail of the skew\n",
        "    max_statements = 20\n",
        "    # Add 1 to all values in the actual data to shift up any 0's to 1 minimum\n",
        "    n_comments = data['n-comments'] + 1\n",
        "    n, p = fit_negative_binomial(n_comments)\n",
        "\n",
        "    # Adjust parameters to fatten the tail\n",
        "    adjusted_n = n / fattening_factor\n",
        "    adjusted_p = adjusted_n / (adjusted_n + n_comments.mean())\n",
        "\n",
        "    # Generate samples from the adjusted negative binomial distribution\n",
        "    samples = np.random.negative_binomial(n=adjusted_n, p=adjusted_p, size=num_participants)\n",
        "\n",
        "    # Ensure at least 1 statement per participant and cap at max_statements\n",
        "    return [min(max(1, sample), max_statements) for sample in samples]\n",
        "\n",
        "@cache_result\n",
        "def sample_statements_per_participant(num_participants):\n",
        "    \"\"\"Sample the number of statements per participant directly from actual data.\"\"\"\n",
        "    max_statements = 20\n",
        "\n",
        "    # Ensure n-comments has at least 1 comment per participant\n",
        "    n_comments = np.maximum(data['n-comments'], 1)\n",
        "\n",
        "    # Sample with replacement from the actual data\n",
        "    samples = np.random.choice(n_comments, size=num_participants, replace=True)\n",
        "\n",
        "    # Cap at max_statements\n",
        "    return [min(sample, max_statements) for sample in samples]\n",
        "\n",
        "@cache_result\n",
        "def calculate_votes_per_participant(num_participants, max_statements):\n",
        "    \"\"\"Calculate the number of votes per participant based on actual data, capped by max_statements.\"\"\"\n",
        "    n_votes = data['n-votes']\n",
        "    n, p = fit_negative_binomial(n_votes)\n",
        "    return [min(max(np.random.negative_binomial(n, p), 1), max_statements) for _ in range(num_participants)]\n",
        "\n",
        "@cache_result\n",
        "def calculate_vote_distribution_per_participant(num_participants):\n",
        "    \"\"\"Calculate the vote distribution per participant based on actual data.\"\"\"\n",
        "    agree_a, agree_b = fit_beta_distribution(data['% agree'])\n",
        "    disagree_a, disagree_b = fit_beta_distribution(data['% disagree'])\n",
        "\n",
        "    distributions = []\n",
        "    for _ in range(num_participants):\n",
        "        agree = np.random.beta(agree_a, agree_b)\n",
        "        disagree = np.random.beta(disagree_a, disagree_b)\n",
        "        pass_prob = max(0, 1 - (agree + disagree))\n",
        "        total = agree + disagree + pass_prob\n",
        "        distributions.append([round(agree/total, 3), round(disagree/total, 3), round(pass_prob/total, 3)])\n",
        "\n",
        "    return distributions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yhSfUWx-4at"
      },
      "source": [
        "## 3.1 Define OpenAI Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDv7AkFF_D9k"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import json\n",
        "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
        "import traceback\n",
        "\n",
        "@retry(wait=wait_random_exponential(min=1, max=10), stop=stop_after_attempt(3))\n",
        "def get_openai_completion(prompt, add_context=None):\n",
        "    \"\"\"Sends a prompt to the OpenAI API and returns the completion, using cache if available.\"\"\"\n",
        "    cache_key = generate_cache_key(prompt, item_type='prompt', add_context=add_context)\n",
        "\n",
        "    if cache_key in llm_cache:\n",
        "        print(\"Using cached response\")\n",
        "        return llm_cache[cache_key]\n",
        "\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an assistant that outputs JSON-formatted data.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0.7\n",
        "        )\n",
        "        completion = response.choices[0].message.content\n",
        "\n",
        "        # Cache the response\n",
        "        llm_cache[cache_key] = completion\n",
        "        print(\"Received response from OpenAI\")\n",
        "        return completion\n",
        "\n",
        "    except Exception as e:\n",
        "        if \"RateLimitError\" in str(type(e)):\n",
        "          retry_after = int(e.headers.get(\"Retry-After\", 10)) if getattr(e, 'headers', None) else 10\n",
        "          print(f\"Rate limit exceeded. Retrying after {retry_after} seconds.\")\n",
        "          time.sleep(retry_after)\n",
        "          raise  # Re-raise the exception to stop execution\n",
        "        else:\n",
        "          print(f\"Error during OpenAI API call: {e}\")\n",
        "          traceback.print_exc()\n",
        "          raise  # Re-raise the exception to stop execution\n",
        "\n",
        "import nest_asyncio\n",
        "import asyncio\n",
        "from asyncio import TimeoutError\n",
        "from traceback import format_exc\n",
        "\n",
        "# Apply nest_asyncio to run with an event loop already running in the notebook\n",
        "nest_asyncio.apply()\n",
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "async def get_openai_completion_async(prompt):\n",
        "    \"\"\"Asynchronous version of get_openai_completion with caching.\"\"\"\n",
        "    print(f\"Sending prompt to OpenAI asynchronously (length: {len(prompt)})\")\n",
        "    loop = asyncio.get_running_loop()\n",
        "    try:\n",
        "        with ThreadPoolExecutor() as pool:\n",
        "            return await asyncio.wait_for(\n",
        "                loop.run_in_executor(pool, get_openai_completion, prompt),\n",
        "                timeout=120  # 120 seconds timeout\n",
        "            )\n",
        "    except TimeoutError:\n",
        "        print(\"API call timed out\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error during API call: {e}\")\n",
        "        traceback.print_exc()\n",
        "        return None\n",
        "\n",
        "# returns json string\n",
        "async def get_openai_completion_chunked(prompt, data, chunk_size=10):\n",
        "    print(f\"Starting chunked completion with {len(data)} items, chunk size {chunk_size}\")\n",
        "    full_response = {\"data\": []}\n",
        "\n",
        "    chunks = [data[i:i+chunk_size] for i in range(0, len(data), chunk_size)]\n",
        "    print(f\"Prepared {len(chunks)} chunks for processing\")\n",
        "\n",
        "\n",
        "\n",
        "    async def process_chunk(chunk_index, chunk):\n",
        "        chunk_prompt = f\"{prompt}\\nProcess the following chunk:\\n{json.dumps(chunk)}\"\n",
        "        try:\n",
        "            response = await get_openai_completion_async(chunk_prompt)\n",
        "            print(f\"Received response for chunk {chunk_index + 1}\")\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing chunk {chunk_index + 1}: {e}\")\n",
        "            traceback.print_exc()\n",
        "            return None\n",
        "\n",
        "    async_responses = await asyncio.gather(*[process_chunk(i, chunk) for i, chunk in enumerate(chunks)])\n",
        "\n",
        "    for chunk_response in async_responses:\n",
        "        if chunk_response:\n",
        "            try:\n",
        "                chunk_data = json.loads(chunk_response)\n",
        "                full_response[\"data\"].extend(chunk_data[\"data\"])\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Error decoding JSON from chunk response: {e}\")\n",
        "\n",
        "    print(f\"Processed {len(async_responses)} chunks\")\n",
        "\n",
        "    return full_response\n",
        "\n",
        "# Example usage of get_openai_completion_chunked\n",
        "async def process_data_async():\n",
        "    # ... other code ...\n",
        "    chunked_response = await get_openai_completion_chunked(prompt, data, chunk_size=10)\n",
        "    # ... process chunked_response ...\n",
        "# In the main execution:\n",
        "# asyncio.run(process_data_async())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ot27l8Ghubc"
      },
      "source": [
        "## 4. User Input Collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVpS-57Zhubc"
      },
      "outputs": [],
      "source": [
        "print(\"### Community Information Collection ###\")\n",
        "if USE_DEFAULT_COMMUNITY:\n",
        "    community_name = community_data['community_name']\n",
        "    community_description = community_data['community_description']\n",
        "    community_goals = community_data['community_goals_for_ai_model']\n",
        "    print(f\"Using default community: {community_name}\")\n",
        "else:\n",
        "    community_name = input(\"Enter the community name: \").strip()\n",
        "    community_description = input(\"Enter the community description: \").strip()\n",
        "    community_goals = input(\"Enter the community goals for the AI model: \").strip()\n",
        "\n",
        "# Consolidate inputs into a single community description\n",
        "full_community_description = f\"{community_description}\\nGoals: {community_goals}\"\n",
        "\n",
        "print(\"\\n### Simulation Parameters Collection ###\")\n",
        "if USE_DEFAULT_COMMUNITY:\n",
        "    num_subgroups = DEFAULT_NUM_SUBGROUPS\n",
        "    num_participants = DEFAULT_NUM_PARTICIPANTS\n",
        "    print(f\"Using default values: {num_subgroups} subgroups, {num_participants} participants\")\n",
        "else:\n",
        "    while True:\n",
        "        try:\n",
        "            num_subgroups = int(input(f\"Enter the number of subgroups (G) [default: {DEFAULT_NUM_SUBGROUPS} ]: \") or f\"{DEFAULT_NUM_SUBGROUPS}\")\n",
        "            if num_subgroups <= 0:\n",
        "                raise ValueError(\"Number of subgroups must be positive.\")\n",
        "            break\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid input: {e}\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            num_participants = int(input(f\"Enter the total number of participants (P) [default: {DEFAULT_NUM_PARTICIPANTS}]: \") or f\"{DEFAULT_NUM_PARTICIPANTS}\")\n",
        "            if num_participants <= 0:\n",
        "                raise ValueError(\"Number of participants must be positive.\")\n",
        "            break\n",
        "        except ValueError as e:\n",
        "            print(f\"Invalid input: {e}\")\n",
        "\n",
        "statement_format = None\n",
        "if not USE_DEFAULT_COMMUNITY:\n",
        "    statement_format = input(\"Enter the statement format (default: 'The best response is one that...'): \").strip()\n",
        "if not statement_format:\n",
        "    statement_format = \"The best response is one that...\"\n",
        "\n",
        "# Function to load LLM cache\n",
        "def load_llm_cache(file_path):\n",
        "    with open(file_path, 'r') as f:\n",
        "        return json.load(f)\n",
        "\n",
        "# Initialize llm_cache with the baseline cache\n",
        "llm_cache = baseline_llm_cache.copy()\n",
        "\n",
        "# Ask if user wants to use an additional saved LLM cache\n",
        "use_saved_cache = input(\"Do you want to use an additional saved LLM cache? (y/n): \").lower().strip() == 'y'\n",
        "if use_saved_cache:\n",
        "    if IN_COLAB:\n",
        "        uploaded = files.upload()\n",
        "        cache_file = list(uploaded.keys())[0]\n",
        "    else:\n",
        "        uploader = upload_files()\n",
        "        while not uploader.value:\n",
        "            pass\n",
        "        cache_file = list(uploader.value.keys())[0]\n",
        "\n",
        "    user_llm_cache = load_llm_cache(cache_file)\n",
        "    # Merge user cache with baseline cache, giving priority to user cache\n",
        "    llm_cache.update(user_llm_cache)\n",
        "    print(f\"Merged {len(user_llm_cache)} items from user cache into LLM cache\")\n",
        "\n",
        "print(f\"Total items in LLM cache: {len(llm_cache)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D4IR5Be-hubd"
      },
      "source": [
        "## 5. Simulation Setup Calculations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jMX8RB37hubd"
      },
      "outputs": [],
      "source": [
        "@cache_result\n",
        "def calculate_participants_per_group(num_subgroups, num_participants):\n",
        "    \"\"\"Distribute participants among groups with variability but no extreme disparities.\"\"\"\n",
        "    base = num_participants // num_subgroups\n",
        "    remainder = num_participants % num_subgroups\n",
        "    participants_per_group = [base] * num_subgroups\n",
        "    for i in range(remainder):\n",
        "        participants_per_group[i] += 1\n",
        "    # Introduce slight variability\n",
        "    for i in range(len(participants_per_group)):\n",
        "        variation = np.random.randint(-base//10, base//10+1)\n",
        "        participants_per_group[i] = max(1, participants_per_group[i] + variation)\n",
        "    total_participants = sum(participants_per_group)\n",
        "    # Adjust if total participants changed due to variability\n",
        "    if total_participants != num_participants:\n",
        "        difference = num_participants - total_participants\n",
        "        for i in range(abs(difference)):\n",
        "            index = i % num_subgroups\n",
        "            if difference > 0:\n",
        "                participants_per_group[index] += 1\n",
        "            else:\n",
        "                participants_per_group[index] = max(1, participants_per_group[index] - 1)\n",
        "    return participants_per_group\n",
        "\n",
        "participants_per_group = calculate_participants_per_group(num_subgroups, num_participants)\n",
        "print(f\"\\nParticipants per group: {participants_per_group}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3unUvwSahubd"
      },
      "source": [
        "## 6. LLM Interaction for Group and Participant Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Vv0xhPXhubd"
      },
      "outputs": [],
      "source": [
        "# Generate subgroups\n",
        "subgroup_generation_prompt = f\"\"\"\n",
        "You are tasked with creating realistic subgroups for a community simulation. Use the following information to generate detailed descriptions:\n",
        "\n",
        "Community Description: {full_community_description}\n",
        "Number of Subgroups: {num_subgroups}\n",
        "\n",
        "For each subgroup:\n",
        "1. Provide a 2-sentence description of the subgroup. This description must start with the words: \"This group consists of individuals who...\"\n",
        "\n",
        "Ensure descriptions are diverse and realistic within the context of the community.\n",
        "\n",
        "Return your response in the following JSON format:\n",
        "{{\"subgroups\": [\n",
        "    {{\"description\": \"This group consists of individuals who <rest of description>\"}},\n",
        "    ...]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "subgroup_generation_response = get_openai_completion(subgroup_generation_prompt)\n",
        "\n",
        "try:\n",
        "    subgroup_data = json.loads(subgroup_generation_response)\n",
        "    subgroups = subgroup_data['subgroups']\n",
        "    print(\"\\nGenerated Subgroups:\")\n",
        "    print(json.dumps(subgroups, indent=4))\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error parsing JSON: {e}\")\n",
        "    subgroups = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wSzapClDgdB"
      },
      "outputs": [],
      "source": [
        "indexed_subgroup_data = [\n",
        "    {\n",
        "        \"subgroup_index\": i,\n",
        "        \"num_participants\": num_participants,\n",
        "        \"description\": subgroup['description']\n",
        "    }\n",
        "    for i, (subgroup, num_participants) in enumerate(zip(subgroups, participants_per_group))\n",
        "]\n",
        "\n",
        "async def generate_participants():\n",
        "    participant_generation_prompt = \"\"\"\n",
        "    Generate unique, 1-sentence descriptions of individuals who could belong to the following subgroups:\n",
        "\n",
        "    For each subgroup in the input data, generate the specified number of participant descriptions.\n",
        "    Ensure descriptions are diverse and realistic within the context of the community.\n",
        "\n",
        "    The description of each participant should take this form: \"A <demographic description> who is <extended description of situation, personality, or goals>.\"\n",
        "    Do not include the name of the participant.\n",
        "\n",
        "    Return your response in the following JSON format:\n",
        "    {\"data\": [{ \"subgroup_index\": 0, \"participants\": [\"Participant 1 description\", \"Participant 2 description\", ...] },\n",
        "              { \"subgroup_index\": 1, \"participants\": [...] },\n",
        "              ...]}\n",
        "    \"\"\"\n",
        "\n",
        "    chunked_response = await get_openai_completion_chunked(\n",
        "        participant_generation_prompt,\n",
        "        indexed_subgroup_data,\n",
        "        chunk_size=1  # Adjust this value as needed\n",
        "    )\n",
        "\n",
        "    return chunked_response\n",
        "\n",
        "# Run the async function to generate participants\n",
        "try:\n",
        "    # This will work in both Jupyter and Colab\n",
        "    loop = asyncio.get_event_loop()\n",
        "    all_participants = loop.run_until_complete(generate_participants())\n",
        "except RuntimeError:\n",
        "    # Fallback for environments where get_event_loop() might fail\n",
        "    all_participants = asyncio.run(generate_participants())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0A6dhnrxUXQ"
      },
      "outputs": [],
      "source": [
        "# Combine subgroups by index from all_subgroups_data and participants from all_participants into group_data\n",
        "group_data = {\n",
        "    \"subgroups\": [\n",
        "        {\n",
        "            \"description\": subgroup_data['description'],\n",
        "            \"participants\": next(item for item in all_participants['data'] if item[\"subgroup_index\"] == subgroup_data[\"subgroup_index\"])[\"participants\"]\n",
        "        }\n",
        "        for subgroup_data in indexed_subgroup_data\n",
        "    ]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "print(\"\\nGenerated Subgroups and Participants:\")\n",
        "print(json.dumps(group_data, indent=4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnSJIMyshubd"
      },
      "source": [
        "## 7. LLM Interaction for Statement Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gU2zlzM82WSj"
      },
      "outputs": [],
      "source": [
        "# Calculate the total number of participants\n",
        "total_participants = sum(len(subgroup['participants']) for subgroup in group_data['subgroups'])\n",
        "\n",
        "# Sample statements per participant - Ensure the number of samples matches the total number of participants\n",
        "statements_per_participant = sample_statements_per_participant(total_participants)\n",
        "\n",
        "# Create an iterator from statements_per_participant\n",
        "statements_iter = iter(statements_per_participant)\n",
        "\n",
        "# Prepare the data structure for chunked processing\n",
        "chunkable_data = []\n",
        "participant_id_counter = 1  # Initialize a counter for unique participant IDs\n",
        "\n",
        "for subgroup_index, subgroup in enumerate(group_data['subgroups']):\n",
        "    for participant in subgroup['participants']:\n",
        "        chunkable_data.append({\n",
        "            'participant_id': participant_id_counter,\n",
        "            'subgroup_index': int(subgroup_index),\n",
        "            'num_statements': int(next(statements_iter)),\n",
        "            'participant': participant\n",
        "        })\n",
        "        participant_id_counter += 1  # Increment the counter for the next participant\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vqdJWr4Ehubd"
      },
      "outputs": [],
      "source": [
        "# Verify that all statements_per_participant values were used\n",
        "if any(True for _ in statements_iter):\n",
        "    print(\"Warning: Not all statements_per_participant values were used.\")\n",
        "\n",
        "# Prepare subgroup descriptions\n",
        "subgroup_descriptions = [\n",
        "    f\"Subgroup {i}: {subgroup['description']}\"\n",
        "    for i, subgroup in enumerate(group_data['subgroups'])\n",
        "]\n",
        "\n",
        "statement_generation_prompt = f\"\"\"\n",
        "Generate statements for a community AI model alignment survey. Use the following information:\n",
        "\n",
        "Community Description: {full_community_description}\n",
        "Statement Format: \"{statement_format}\"\n",
        "\n",
        "Subgroup Descriptions:\n",
        "{json.dumps(subgroup_descriptions, indent=2)}\n",
        "\n",
        "For each participant in the input data, generate the specified number of statements that align with their subgroup and individual characteristics. Ensure statements are diverse and relevant to the community's goals.\n",
        "\n",
        "The input data format is:\n",
        "[participant_id, subgroup_index, number_of_statements_to_generate, participant_description]\n",
        "\n",
        "Return your response in the following JSON format:\n",
        "{{\n",
        "    \"data\": [\n",
        "        {{\n",
        "            \"participant_id\": \"<participant_id>\",\n",
        "            \"statements\": [\"Statement 1\", \"Statement 2\", ...]\n",
        "        }},\n",
        "        ...\n",
        "    ]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "async def generate_statements():\n",
        "    chunked_response = await get_openai_completion_chunked(\n",
        "        statement_generation_prompt,\n",
        "        chunkable_data,\n",
        "        chunk_size=10  # Adjust this value as needed\n",
        "    )\n",
        "    return chunked_response\n",
        "\n",
        "# Run the async function to generate statements\n",
        "try:\n",
        "    # This will work in both Jupyter and Colab\n",
        "    loop = asyncio.get_event_loop()\n",
        "    all_statements = loop.run_until_complete(generate_statements())\n",
        "except RuntimeError:\n",
        "    # Fallback for environments where get_event_loop() might fail\n",
        "    all_statements = asyncio.run(generate_statements())\n",
        "\n",
        "# convert list of dict objects: [{\"participant_id\":<participant_id>, \"statements\":[<statements>]}] to a dict with keys: {<participant_id>:[<statements>],}\n",
        "participant_statements = {item['participant_id']: item['statements'] for item in all_statements['data']}\n",
        "\n",
        "try:\n",
        "    print(\"\\nGenerated Participant Statements:\")\n",
        "    print(json.dumps(participant_statements, indent=4))\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"Error parsing JSON: {e}\")\n",
        "    participant_statements = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2k2Dy8y-0GR"
      },
      "outputs": [],
      "source": [
        "# Verify that the number of statements per participant is consistent\n",
        "print(statements_per_participant)\n",
        "print([len(s) for s in participant_statements.values()])\n",
        "print([i['num_statements'] for i in chunkable_data])\n",
        "#skip: assert statements_per_participant == [len(s) for s in participant_statements.values()] == [len(i['statements']) for i in  all_statements['data']] == [i['num_statements'] for i in chunkable_data]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHrvse3Qhubd"
      },
      "source": [
        "## 8. LLM Interaction for Vote Simulation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9GBW20Mhubd"
      },
      "outputs": [],
      "source": [
        "print(\"Starting vote simulation process...\")\n",
        "\n",
        "# Prepare numbered statements list\n",
        "statements_list = []\n",
        "statement_id = 1\n",
        "for participant_id, statements in participant_statements.items():\n",
        "    for stmt in statements:\n",
        "        statements_list.append({'statement_id': statement_id, 'text': stmt})\n",
        "        statement_id += 1\n",
        "\n",
        "print(f\"Prepared {len(statements_list)} statements for {len(participant_statements)} participants\")\n",
        "\n",
        "numbered_statements_list = json.dumps(statements_list, indent=4)\n",
        "\n",
        "# Prepare participants and assignments data\n",
        "max_statements = len(statements_list)\n",
        "votes_per_participant = calculate_votes_per_participant(len(participant_statements), max_statements)\n",
        "vote_distributions = calculate_vote_distribution_per_participant(len(participant_statements))\n",
        "\n",
        "print(f\"Calculated votes per participant and vote distributions\")\n",
        "\n",
        "chunkable_data = []\n",
        "for i, (participant_id, statements) in enumerate(participant_statements.items()):\n",
        "    num_votes = votes_per_participant[i]\n",
        "    available_statements = [s['statement_id'] for s in statements_list]\n",
        "    assigned_statements = random.sample(available_statements, min(num_votes, len(available_statements)))\n",
        "    chunkable_data.append({\n",
        "        'participant_id': participant_id,\n",
        "        'statements_assigned': assigned_statements,\n",
        "        'vote_distribution': dict(zip(['agree', 'disagree', 'pass'], vote_distributions[i]))\n",
        "    })\n",
        "\n",
        "print(f\"Prepared chunkable data for {len(chunkable_data)} participants\")\n",
        "\n",
        "vote_simulation_prompt = f\"\"\"\n",
        "Simulate voting patterns for a community AI model alignment survey. Use the following information:\n",
        "\n",
        "Community Description: {full_community_description}\n",
        "Statements:\n",
        "{numbered_statements_list}\n",
        "\n",
        "For each participant in the input data, determine how they would likely vote on their assigned statements. Use the following voting options:\n",
        "1 = Agree\n",
        "-1 = Disagree\n",
        "0 = Pass\n",
        "\n",
        "Ensure that each participant's voting pattern closely matches their target vote distribution.\n",
        "\n",
        "The input data format is:\n",
        "[participant_id, statements_assigned, vote_distribution]\n",
        "\n",
        "Return your response in the following JSON format:\n",
        "{{\n",
        "    \"data\": [\n",
        "        {{\n",
        "            \"participant_id\": \"Unique identifier\",\n",
        "            \"votes\": {{\"statement_id\": vote, ...}}\n",
        "        }},\n",
        "        ...\n",
        "    ]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "print(\"Prepared vote simulation prompt\")\n",
        "\n",
        "async def simulate_votes():\n",
        "    print(\"Starting vote simulation...\")\n",
        "    chunked_response = await get_openai_completion_chunked(\n",
        "        vote_simulation_prompt,\n",
        "        chunkable_data,\n",
        "        chunk_size=4  # Adjust this value as needed\n",
        "    )\n",
        "    print(\"Completed vote simulation\")\n",
        "    return chunked_response\n",
        "\n",
        "# Run the async function to simulate votes\n",
        "print(\"Initiating async vote simulation...\")\n",
        "try:\n",
        "    loop = asyncio.get_event_loop()\n",
        "    vote_simulation_response = loop.run_until_complete(simulate_votes())\n",
        "    print(\"Async vote simulation completed\")\n",
        "except RuntimeError:\n",
        "    print(\"RuntimeError occurred, falling back to asyncio.run()\")\n",
        "    vote_simulation_response = asyncio.run(simulate_votes())\n",
        "except Exception as e:\n",
        "    print(f\"An unexpected error occurred: {e}\")\n",
        "    vote_simulation_response = None\n",
        "\n",
        "if vote_simulation_response:\n",
        "    try:\n",
        "        vote_data = vote_simulation_response['data']\n",
        "        # make sure vote statement_ids are ints\n",
        "        participant_votes = {item['participant_id']: {int(stmt_id): vote for stmt_id, vote in item['votes'].items()} for item in vote_data}\n",
        "        # participant_votes = { <participant_id>: {<statement_id>: <vote>, ...}, ... }\n",
        "        print(\"\\nSimulated Votes:\")\n",
        "        print(json.dumps(participant_votes, indent=4))\n",
        "    except (json.JSONDecodeError, KeyError) as e:\n",
        "        print(f\"Error processing vote data: {e}\")\n",
        "        participant_votes = {}\n",
        "else:\n",
        "    print(\"No vote simulation response received\")\n",
        "    participant_votes = {}\n",
        "\n",
        "print(\"Vote simulation process completed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K1wJK-Bhube"
      },
      "source": [
        "## 9. Vote Matrix Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMKvSFXIhube"
      },
      "outputs": [],
      "source": [
        "# Create empty matrix (rows = participants, columns = statements)\n",
        "participant_ids = list(participant_votes.keys())\n",
        "statement_ids = sorted(set(stmt_id for votes in participant_votes.values() for stmt_id in votes))\n",
        "\n",
        "vote_matrix = pd.DataFrame(index=participant_ids, columns=statement_ids)\n",
        "\n",
        "# Populate matrix with votes\n",
        "for participant_id, votes in participant_votes.items():\n",
        "    for stmt_id, vote_value in votes.items():\n",
        "        vote_matrix.at[participant_id, stmt_id] = vote_value\n",
        "\n",
        "# Convert data types\n",
        "vote_matrix = vote_matrix.apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F_W1gQMhube"
      },
      "source": [
        "## 10. Results Visualization and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zc_-BTXhube"
      },
      "outputs": [],
      "source": [
        "import matplotlib.colors as mcolors\n",
        "\n",
        "# Create a custom colormap\n",
        "cmap = mcolors.ListedColormap(['red', 'gray', 'green'])\n",
        "bounds = [-1.5, -0.5, 0.5, 1.5]\n",
        "norm = mcolors.BoundaryNorm(bounds, cmap.N)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.imshow(vote_matrix.fillna(0), aspect='auto', cmap=cmap, norm=norm, interpolation='none')\n",
        "\n",
        "# Create a custom colorbar\n",
        "cbar = plt.colorbar(ticks=[-1, 0, 1])\n",
        "cbar.set_ticklabels(['Disagree', 'Pass', 'Agree'])\n",
        "cbar.set_label('Vote')\n",
        "\n",
        "plt.xlabel('Statements')\n",
        "plt.ylabel('Participants')\n",
        "plt.title('Vote Matrix Heatmap')\n",
        "plt.show()\n",
        "\n",
        "# Calculate and display vote distribution statistics\n",
        "vote_counts = vote_matrix.stack().value_counts()\n",
        "print(\"\\n### Vote Distribution Statistics ###\")\n",
        "print(vote_counts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tW8ce07XLTH9"
      },
      "outputs": [],
      "source": [
        "# Convert vote_matrix to a list of lists\n",
        "vote_matrix_list = vote_matrix.values.tolist()\n",
        "\n",
        "# Replace NaN values with None\n",
        "vote_matrix_list = [[None if pd.isna(value) else int(value) for value in row] for row in vote_matrix_list]\n",
        "\n",
        "# Print the result\n",
        "print(\"Vote matrix as a list of lists:\")\n",
        "print(\"[\")\n",
        "for row in vote_matrix_list:\n",
        "    print(f\"    {row},\")\n",
        "print(\"]\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Impute Missing Votes (Using Jaccard Similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "from collections import defaultdict\n",
        "\n",
        "def jaccard_similarity(vote_matrix):\n",
        "    def jaccard_distance(a, b):\n",
        "        a_valid = ~np.isnan(a)\n",
        "        b_valid = ~np.isnan(b)\n",
        "        common_valid = a_valid & b_valid\n",
        "\n",
        "        if not np.any(common_valid):\n",
        "            return 1.0  # Maximum distance if no common valid votes\n",
        "\n",
        "        a_agree = set(np.where((a == 1) & common_valid)[0])\n",
        "        b_agree = set(np.where((b == 1) & common_valid)[0])\n",
        "        a_disagree = set(np.where((a == -1) & common_valid)[0])\n",
        "        b_disagree = set(np.where((b == -1) & common_valid)[0])\n",
        "\n",
        "        j_agree = len(a_agree & b_agree) / len(a_agree | b_agree) if len(a_agree | b_agree) > 0 else 0\n",
        "        j_disagree = len(a_disagree & b_disagree) / len(a_disagree | b_disagree) if len(a_disagree | b_disagree) > 0 else 0\n",
        "\n",
        "        return 1 - (j_agree + j_disagree) / 2\n",
        "\n",
        "    # Calculate distance matrix\n",
        "    distance_matrix = squareform(pdist(vote_matrix.fillna(np.nan), metric=jaccard_distance))\n",
        "    # Convert to similarity matrix\n",
        "    similarity_matrix = 1 - distance_matrix\n",
        "    return similarity_matrix\n",
        "\n",
        "def impute_missing_values_jaccard_similarity(vote_matrix, n_neighbors=5):\n",
        "    # Convert vote_matrix to numpy array\n",
        "    votes = vote_matrix.values\n",
        "\n",
        "    # Calculate similarity matrix\n",
        "    similarity_matrix = jaccard_similarity(vote_matrix)\n",
        "\n",
        "    # Impute missing values\n",
        "    imputed_votes = np.copy(votes)\n",
        "    for i in range(votes.shape[0]):\n",
        "        missing_indices = np.where(np.isnan(votes[i]))[0]\n",
        "        if len(missing_indices) == 0:\n",
        "            continue\n",
        "\n",
        "        similar_indices = np.argsort(similarity_matrix[i])[::-1]  # Indices of participants sorted by similarity\n",
        "        for j in missing_indices:\n",
        "            sim_votes = []\n",
        "            sim_weights = []\n",
        "            for idx in similar_indices:\n",
        "                if not np.isnan(votes[idx, j]) and idx != i:\n",
        "                    sim_votes.append(votes[idx, j])\n",
        "                    sim_weights.append(similarity_matrix[i, idx])\n",
        "                if len(sim_votes) >= n_neighbors:\n",
        "                    break\n",
        "            if sim_votes:\n",
        "                # Check if sim_weights sum to zero, for edge case:\n",
        "                # if participant has no common valid votes with any other participant for a particular statement, causing their similarity to be zero with all others.\n",
        "                if np.sum(sim_weights) == 0:\n",
        "                    # Handle the case where weights sum to zero (e.g., by setting a default value)\n",
        "                    imputed_votes[i, j] = 0  # Or another suitable default\n",
        "                else:\n",
        "                    imputed_votes[i, j] = np.average(sim_votes, weights=sim_weights)\n",
        "            else:\n",
        "                imputed_votes[i, j] = 0  # Default value if no similar votes found\n",
        "\n",
        "    imputed_vote_matrix = pd.DataFrame(imputed_votes, index=vote_matrix.index, columns=vote_matrix.columns)\n",
        "    return imputed_vote_matrix\n",
        "\n",
        "# Impute missing values\n",
        "imputed_vote_matrix = impute_missing_values_jaccard_similarity(vote_matrix, n_neighbors=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13. Calculate Groups (Using PCA & K-means)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 13. Determine Optimal Number of PCA Components and Optimal K\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from kneed import KneeLocator\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# Perform PCA\n",
        "max_pca_components = min(100, imputed_vote_matrix.shape[1])\n",
        "pca = PCA(n_components=max_pca_components)\n",
        "pca.fit(imputed_vote_matrix)\n",
        "\n",
        "# Calculate explained variance ratio\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "# Find optimal number of components using elbow method\n",
        "n_components = range(1, max_pca_components + 1)\n",
        "kneedle = KneeLocator(n_components, explained_variance_ratio, S=1.0, curve=\"convex\", direction=\"decreasing\")\n",
        "optimal_components = kneedle.elbow if kneedle.elbow else max_pca_components\n",
        "\n",
        "print(f\"Optimal number of PCA components: {optimal_components}\")\n",
        "\n",
        "# Plot Scree Plot\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(n_components, explained_variance_ratio, 'bo-')\n",
        "plt.axvline(x=optimal_components, color='r', linestyle='--', label=f'Elbow at {optimal_components}')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.title('Scree Plot')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Project data onto optimal number of components\n",
        "pca_optimal = PCA(n_components=optimal_components)\n",
        "pca_projection = pca_optimal.fit_transform(imputed_vote_matrix)\n",
        "\n",
        "# Determine Optimal K using Silhouette Method over K-values 2 through 9\n",
        "k_values = range(2, 10)\n",
        "silhouette_scores = []\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    labels = kmeans.fit_predict(pca_projection)\n",
        "    score = silhouette_score(pca_projection, labels)\n",
        "    silhouette_scores.append(score)\n",
        "    print(f\"Silhouette Score for k={k}: {score:.4f}\")\n",
        "\n",
        "# Find optimal K\n",
        "optimal_k = k_values[np.argmax(silhouette_scores)]\n",
        "print(f\"Optimal number of clusters (K): {optimal_k}\")\n",
        "\n",
        "# Plot Silhouette Scores\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(k_values, silhouette_scores, 'bo-')\n",
        "plt.xlabel('Number of Clusters (K)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs Number of Clusters')\n",
        "plt.show()\n",
        "\n",
        "# Run KMeans Clustering with Optimal K\n",
        "kmeans_optimal = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "cluster_labels = kmeans_optimal.fit_predict(pca_projection)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "imputed_vote_matrix['Cluster'] = cluster_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14. Compute Group-Aware Consensus Scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_gac_scores(vote_matrix, groups):\n",
        "    \"\"\"\n",
        "    Calculate Group-Aware Consensus (GAC) scores for each statement.\n",
        "\n",
        "    :param vote_matrix: pandas DataFrame of votes (participants as rows, statements as columns)\n",
        "    :param groups: list or array of group assignments corresponding to each participant\n",
        "    :return: dict of {statement_id: gac_score}\n",
        "    \"\"\"\n",
        "    gac_scores = {}\n",
        "    \n",
        "    # Convert groups to a numpy array if it's not already\n",
        "    if not isinstance(groups, np.ndarray):\n",
        "        group_array = np.array(groups)\n",
        "    else:\n",
        "        group_array = groups\n",
        "\n",
        "    unique_groups = np.unique(group_array)\n",
        "\n",
        "    # Iterate over each statement (column in vote_matrix)\n",
        "    for statement_idx in vote_matrix.columns:\n",
        "        statement_votes = vote_matrix[statement_idx].values\n",
        "        \n",
        "        gac = 1.0\n",
        "        # Iterate over each group\n",
        "        for group in unique_groups:\n",
        "            group_votes = statement_votes[group_array == group]\n",
        "            # Exclude NaN values\n",
        "            group_votes = group_votes[~np.isnan(group_votes)]\n",
        "            \n",
        "            # Sum of positive votes (agrees)\n",
        "            sum_agrees = np.sum(np.maximum(group_votes, 0))\n",
        "            # Sum of absolute values of votes\n",
        "            sum_abs_votes = np.sum(np.abs(group_votes))\n",
        "            \n",
        "            # Calculate probability of agreement for this group\n",
        "            if sum_abs_votes == 0:\n",
        "                p_agree = 0.5  # Neutral if no votes\n",
        "            else:\n",
        "                p_agree = (1 + sum_agrees) / (2 + sum_abs_votes)\n",
        "            \n",
        "            gac *= p_agree  # Multiply probabilities across groups\n",
        "        \n",
        "        gac_scores[statement_idx] = gac\n",
        "\n",
        "    return gac_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate GAC Scores for each Statement\n",
        "\n",
        "# Ensure 'cluster_labels' from KMeans clustering is available\n",
        "# Since 'imputed_vote_matrix' includes the 'Cluster' column, extract it\n",
        "cluster_labels = imputed_vote_matrix['Cluster'].values\n",
        "\n",
        "# Remove 'Cluster' column to get the original vote matrix\n",
        "vote_matrix_no_cluster = imputed_vote_matrix.drop(columns=['Cluster'])\n",
        "\n",
        "# Use the existing 'calculate_gac_scores' function\n",
        "gac_scores = calculate_gac_scores(vote_matrix_no_cluster, cluster_labels)\n",
        "\n",
        "# Map GAC scores to statements\n",
        "statements_df = pd.DataFrame(statements_list)\n",
        "# Adjust the index to match the statement IDs\n",
        "statements_df = statements_df.set_index('statement_id')\n",
        "statements_df['GAC_Score'] = statements_df.index.map(gac_scores)\n",
        "\n",
        "# Reset index to include 'statement_id' as a column\n",
        "statements_df = statements_df.reset_index()\n",
        "\n",
        "# Sort statements by GAC score\n",
        "statements_df = statements_df.sort_values(by='GAC_Score', ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 15. Resulting Constitution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 15. Display Statements Ordered by GAC Score with Cutoff Threshold\n",
        "\n",
        "# Define a minimum required consensus threshold\n",
        "consensus_threshold = 0.6  # Adjust this value as needed\n",
        "\n",
        "# Separate statements above and below the threshold\n",
        "above_threshold = statements_df[statements_df['GAC_Score'] >= consensus_threshold]\n",
        "below_threshold = statements_df[statements_df['GAC_Score'] < consensus_threshold]\n",
        "\n",
        "# Print statements above the threshold\n",
        "print(\"Statements above consensus threshold:\\n\")\n",
        "for idx, row in above_threshold.iterrows():\n",
        "    print(f\"Statement ID: {row['statement_id']}\")\n",
        "    print(f\"GAC Score: {row['GAC_Score']:.4f}\")\n",
        "    print(f\"Text: {row['text']}\\n\")\n",
        "\n",
        "# Print a cutoff line\n",
        "print(\"\\n------ Statements Below Consensus Threshold ------\\n\")\n",
        "\n",
        "# Print statements below the threshold\n",
        "for idx, row in below_threshold.iterrows():\n",
        "    print(f\"Statement ID: {row['statement_id']}\")\n",
        "    print(f\"GAC Score: {row['GAC_Score']:.4f}\")\n",
        "    print(f\"Text: {row['text']}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 16. Export Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from IPython.display import FileLink\n",
        "\n",
        "# Create a dictionary mapping statement_id to statement text and GAC score\n",
        "statement_dict = {\n",
        "    item['statement_id']: {\n",
        "        'text': item['text'],\n",
        "        'gac_score': gac_scores.get(item['statement_id'], 0)\n",
        "    } for item in statements_list\n",
        "}\n",
        "\n",
        "# Create a reverse mapping of statement text to id\n",
        "text_to_id = {item['text']: item['statement_id'] for item in statements_list}\n",
        "\n",
        "# Prepare the data structure\n",
        "export_data = {\n",
        "    \"community_info\": {\n",
        "        \"name\": community_name,\n",
        "        \"description\": community_description,\n",
        "        \"goals\": community_goals\n",
        "    },\n",
        "    \"user_inputs\": {\n",
        "        \"num_subgroups\": num_subgroups,\n",
        "        \"num_participants\": num_participants\n",
        "    },\n",
        "    \"statement_format\": statement_format,\n",
        "    \"statements\": [\n",
        "        {\"id\": stmt_id, \"text\": info['text'], \"gac_score\": info['gac_score']}\n",
        "        for stmt_id, info in statement_dict.items()\n",
        "    ],\n",
        "    \"subgroups\": [\n",
        "        {\n",
        "            \"index\": i,\n",
        "            \"description\": subgroup[\"description\"],\n",
        "            \"participants\": [\n",
        "                {\n",
        "                    \"id\": participant_id,\n",
        "                    \"description\": participant,\n",
        "                    \"statements\": [\n",
        "                        {\"id\": text_to_id[stmt], \"text\": stmt}\n",
        "                        for stmt in participant_statements.get(int(participant_id), [])\n",
        "                        if stmt in text_to_id\n",
        "                    ],\n",
        "                    \"votes\": {int(k): v for k, v in participant_votes.get(int(participant_id), {}).items()},\n",
        "                    \"cluster_group\": int(imputed_vote_matrix.loc[int(participant_id), 'Cluster']),\n",
        "                    \"imputed_votes\": {\n",
        "                        int(col): float(imputed_vote_matrix.loc[int(participant_id), col])\n",
        "                        for col in imputed_vote_matrix.columns\n",
        "                        if col != 'Cluster' and pd.isna(vote_matrix.loc[int(participant_id), col])\n",
        "                    }\n",
        "                }\n",
        "                for participant_id, participant in enumerate(subgroup[\"participants\"], start=1)\n",
        "            ]\n",
        "        }\n",
        "        for i, subgroup in enumerate(group_data[\"subgroups\"])\n",
        "    ],\n",
        "    \"constitution\": {\n",
        "        \"gac_score_threshold\": consensus_threshold,\n",
        "        \"statements\": [\n",
        "            {\n",
        "                \"id\": int(row['statement_id']),\n",
        "                \"text\": row['text'],\n",
        "                \"gac_score\": float(row['GAC_Score'])\n",
        "            }\n",
        "            for _, row in above_threshold.iterrows()\n",
        "        ]\n",
        "    }\n",
        "}\n",
        "\n",
        "def convert_to_serializable(obj):\n",
        "    if isinstance(obj, np.integer):\n",
        "        return int(obj)\n",
        "    elif isinstance(obj, np.floating):\n",
        "        return float(obj)\n",
        "    elif isinstance(obj, np.ndarray):\n",
        "        return obj.tolist()\n",
        "    else:\n",
        "        return obj\n",
        "# Export the data to a JSON file\n",
        "with open('simulation_data.json', 'w') as f:\n",
        "    json.dump(export_data, f, indent=2)\n",
        "\n",
        "print(\"Simulation data exported to 'simulation_data.json'\")\n",
        "\n",
        "# Export the LLM cache\n",
        "with open('llm_cache.json', 'w') as f:\n",
        "    json.dump(llm_cache, f, indent=2, default=convert_to_serializable)\n",
        "\n",
        "print(\"LLM cache exported to 'llm_cache.json'\")\n",
        "\n",
        "# Provide download links for Colab or local\n",
        "if IN_COLAB:\n",
        "    from google.colab import files\n",
        "    files.download('simulation_data.json')\n",
        "    files.download('llm_cache.json')\n",
        "else:\n",
        "    from IPython.display import FileLink\n",
        "    display(FileLink('simulation_data.json'))\n",
        "    display(FileLink('llm_cache.json'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-6jFAI_zhuba",
        "IgOUSi2Hhubc",
        "UHn6gXQ4hubc",
        "5yhSfUWx-4at",
        "9Ot27l8Ghubc",
        "D4IR5Be-hubd",
        "3unUvwSahubd",
        "jnSJIMyshubd",
        "lHrvse3Qhubd",
        "_K1wJK-Bhube",
        "7F_W1gQMhube",
        "YSt5hQmie0U_"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
