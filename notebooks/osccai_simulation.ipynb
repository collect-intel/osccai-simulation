{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OSCCAI Simulation Notebook\n",
    "\n",
    "## Usage Instructions\n",
    "\n",
    "This notebook simulates output from an Open Source Collective Constitutional AI (OSCCAI) tool.\n",
    "Please ensure you have the necessary libraries installed as specified in the `requirements.txt` file.\n",
    "You will need an OpenAI API key to run this notebook. Set it as an environment variable or enter it when prompted.\n",
    "\n",
    "**Required Setup:**\n",
    "- Install required libraries using `pip install -r requirements.txt`\n",
    "- Set your OpenAI API key:\n",
    "  - Option 1: Set as an environment variable `OPENAI_API_KEY`\n",
    "  - Option 2: Enter it when prompted in the notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run this cell to install required packages\n",
    "# !pip install numpy pandas matplotlib openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from getpass import getpass\n",
    "from IPython.display import display, Markdown\n",
    "from google.colab import files\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import beta, nbinom\n",
    "import random\n",
    "from openai import OpenAI\n",
    "\n",
    "# Set up OpenAI API key\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "api_key=getpass(\"Please enter your OpenAI API key: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Upload and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get actual data to base distributions on\n",
    "print(\"Please upload your Polis data CSV file.\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Load the uploaded CSV into a DataFrame\n",
    "filename = list(uploaded.keys())[0]\n",
    "data = pd.read_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define Simulation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_beta_distribution(data):\n",
    "    \"\"\"Fit a beta distribution to the given data.\"\"\"\n",
    "    data_cleaned = data.clip(lower=0.001, upper=0.999)\n",
    "    a, b, _, _ = beta.fit(data_cleaned, floc=0, fscale=1)\n",
    "    return a, b\n",
    "\n",
    "def fit_negative_binomial(data):\n",
    "    \"\"\"Fit a negative binomial distribution to the given data.\"\"\"\n",
    "    mean = data.mean()\n",
    "    var = data.var()\n",
    "    n = (mean ** 2) / (var - mean) if var > mean else 10\n",
    "    p = mean / (mean + n)\n",
    "    return n, p\n",
    "\n",
    "def calculate_statements_per_participant(num_participants):\n",
    "    \"\"\"Calculate the number of statements per participant based on actual data.\"\"\"\n",
    "    n_comments = data['n-comments']\n",
    "    n, p = fit_negative_binomial(n_comments)\n",
    "    return [max(np.random.negative_binomial(n, p), 1) for _ in range(num_participants)]\n",
    "\n",
    "def calculate_votes_per_participant(num_participants):\n",
    "    \"\"\"Calculate the number of votes per participant based on actual data.\"\"\"\n",
    "    n_votes = data['n-votes']\n",
    "    n, p = fit_negative_binomial(n_votes)\n",
    "    return [max(np.random.negative_binomial(n, p), 1) for _ in range(num_participants)]\n",
    "\n",
    "def calculate_vote_distribution_per_participant(num_participants):\n",
    "    \"\"\"Calculate the vote distribution per participant based on actual data.\"\"\"\n",
    "    agree_a, agree_b = fit_beta_distribution(data['% agree'])\n",
    "    disagree_a, disagree_b = fit_beta_distribution(data['% disagree'])\n",
    "    \n",
    "    distributions = []\n",
    "    for _ in range(num_participants):\n",
    "        agree = np.random.beta(agree_a, agree_b)\n",
    "        disagree = np.random.beta(disagree_a, disagree_b)\n",
    "        pass_prob = max(0, 1 - (agree + disagree))\n",
    "        total = agree + disagree + pass_prob\n",
    "        distributions.append([round(agree/total, 3), round(disagree/total, 3), round(pass_prob/total, 3)])\n",
    "    \n",
    "    return distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. User Input Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"### Community Information Collection ###\")\n",
    "community_name = input(\"Enter the community name: \").strip()\n",
    "community_description = input(\"Enter the community description: \").strip()\n",
    "community_goals = input(\"Enter the community goals for the AI model: \").strip()\n",
    "\n",
    "# Consolidate inputs into a single community description\n",
    "full_community_description = f\"{community_description}\\nGoals: {community_goals}\"\n",
    "\n",
    "print(\"\\n### Simulation Parameters Collection ###\")\n",
    "while True:\n",
    "    try:\n",
    "        num_subgroups = int(input(\"Enter the number of subgroups (G): \"))\n",
    "        if num_subgroups <= 0:\n",
    "            raise ValueError(\"Number of subgroups must be positive.\")\n",
    "        break\n",
    "    except ValueError as e:\n",
    "        print(f\"Invalid input: {e}\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        num_participants = int(input(\"Enter the total number of participants (P): \"))\n",
    "        if num_participants <= 0:\n",
    "            raise ValueError(\"Number of participants must be positive.\")\n",
    "        break\n",
    "    except ValueError as e:\n",
    "        print(f\"Invalid input: {e}\")\n",
    "\n",
    "statement_format = input(\"Enter the statement format (default: 'The best response is one that...'): \").strip()\n",
    "if not statement_format:\n",
    "    statement_format = \"The best response is one that...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simulation Setup Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_participants_per_group(num_subgroups, num_participants):\n",
    "    \"\"\"Distribute participants among groups with variability but no extreme disparities.\"\"\"\n",
    "    base = num_participants // num_subgroups\n",
    "    remainder = num_participants % num_subgroups\n",
    "    participants_per_group = [base] * num_subgroups\n",
    "    for i in range(remainder):\n",
    "        participants_per_group[i] += 1\n",
    "    # Introduce slight variability\n",
    "    for i in range(len(participants_per_group)):\n",
    "        variation = np.random.randint(-base//10, base//10+1)\n",
    "        participants_per_group[i] = max(1, participants_per_group[i] + variation)\n",
    "    total_participants = sum(participants_per_group)\n",
    "    # Adjust if total participants changed due to variability\n",
    "    if total_participants != num_participants:\n",
    "        difference = num_participants - total_participants\n",
    "        for i in range(abs(difference)):\n",
    "            index = i % num_subgroups\n",
    "            if difference > 0:\n",
    "                participants_per_group[index] += 1\n",
    "            else:\n",
    "                participants_per_group[index] = max(1, participants_per_group[index] - 1)\n",
    "    return participants_per_group\n",
    "\n",
    "participants_per_group = calculate_participants_per_group(num_subgroups, num_participants)\n",
    "print(f\"\\nParticipants per group: {participants_per_group}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. LLM Interaction for Group and Participant Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_openai_completion(prompt, max_tokens=1500):\n",
    "    \"\"\"Sends a prompt to the OpenAI API and returns the completion.\"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(model=\"gpt-4\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an assistant that outputs JSON-formatted data.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=0.7)\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(f\"Error during OpenAI API call: {e}\")\n",
    "        return None\n",
    "\n",
    "group_generation_prompt = f\"\"\"\n",
    "You are tasked with creating realistic subgroups and participants for a community simulation. Use the following information to generate detailed descriptions:\n",
    "\n",
    "Community Description: {full_community_description}\n",
    "Number of Subgroups: {num_subgroups}\n",
    "Participants per Group: {participants_per_group}\n",
    "\n",
    "For each subgroup:\n",
    "1. Provide a 2-sentence description of the subgroup.\n",
    "2. Generate the specified number of unique, 1-sentence descriptions of individuals who could belong to this subgroup.\n",
    "\n",
    "Ensure descriptions are diverse and realistic within the context of the community.\n",
    "\n",
    "Return your response in the following JSON format:\n",
    "{{\"subgroups\": [\n",
    "    {{\"description\": \"Subgroup description\",\n",
    "    \"participants\": [\"Participant 1 description\", \"Participant 2 description\", ...]}},\n",
    "    ...]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "group_generation_response = get_openai_completion(group_generation_prompt)\n",
    "\n",
    "try:\n",
    "    group_data = json.loads(group_generation_response)\n",
    "    subgroups = group_data['subgroups']\n",
    "    print(\"\\nGenerated Subgroups and Participants:\")\n",
    "    print(json.dumps(group_data, indent=4))\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing JSON: {e}\")\n",
    "    subgroups = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. LLM Interaction for Statement Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements_per_participant = calculate_statements_per_participant(num_participants)\n",
    "subgroups_and_participants_json = json.dumps(group_data, indent=4)\n",
    "\n",
    "statement_generation_prompt = f\"\"\"\n",
    "Generate statements for a community AI model alignment survey. Use the following information:\n",
    "\n",
    "Community Description: {full_community_description}\n",
    "Statement Format: \"{statement_format}\"\n",
    "\n",
    "For each participant, generate a unique number of statements that align with their subgroup and individual characteristics. The number of statements for each participant is provided in the JSON below. Ensure statements are diverse and relevant to the community's goals.\n",
    "\n",
    "Subgroups and Participants:\n",
    "{subgroups_and_participants_json}\n",
    "\n",
    "Number of statements per participant:\n",
    "{json.dumps(dict(zip(range(num_participants), statements_per_participant)))}\n",
    "\n",
    "Return your response in the following JSON format:\n",
    "{{\n",
    "    \"statements\": [\n",
    "        {{\n",
    "            \"participant_id\": \"Unique identifier\",\n",
    "            \"statements\": [\"Statement 1\", \"Statement 2\", ...]\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "statement_generation_response = get_openai_completion(statement_generation_prompt)\n",
    "\n",
    "try:\n",
    "    statement_data = json.loads(statement_generation_response)\n",
    "    participant_statements = statement_data['statements']\n",
    "    print(\"\\nGenerated Participant Statements:\")\n",
    "    print(json.dumps(statement_data, indent=4))\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing JSON: {e}\")\n",
    "    participant_statements = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. LLM Interaction for Vote Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare numbered statements list\n",
    "statements_list = []\n",
    "statement_id = 1\n",
    "participant_ids = []\n",
    "for participant in participant_statements:\n",
    "    participant_ids.append(participant['participant_id'])\n",
    "    for stmt in participant['statements']:\n",
    "        statements_list.append({'statement_id': statement_id, 'text': stmt})\n",
    "        statement_id += 1\n",
    "\n",
    "numbered_statements_list = json.dumps(statements_list, indent=4)\n",
    "\n",
    "# Prepare participants and assignments data\n",
    "votes_per_participant = calculate_votes_per_participant(num_participants)\n",
    "vote_distributions = calculate_vote_distribution_per_participant(num_participants)\n",
    "\n",
    "participants_and_assignments = []\n",
    "for i, participant in enumerate(participant_statements):\n",
    "    participants_and_assignments.append({\n",
    "        'participant_id': participant['participant_id'],\n",
    "        'statements_assigned': random.sample([s['statement_id'] for s in statements_list], votes_per_participant[i]),\n",
    "        'vote_distribution': dict(zip(['agree', 'disagree', 'pass'], vote_distributions[i]))\n",
    "    })\n",
    "participants_and_assignments_json = json.dumps(participants_and_assignments, indent=4)\n",
    "\n",
    "vote_simulation_prompt = f\"\"\"\n",
    "Simulate voting patterns for a community AI model alignment survey. Use the following information:\n",
    "\n",
    "Community Description: {full_community_description}\n",
    "Statements:\n",
    "{numbered_statements_list}\n",
    "\n",
    "For each participant, determine how they would likely vote on their assigned statements. Use the following voting options:\n",
    "1 = Agree\n",
    "-1 = Disagree\n",
    "0 = Pass\n",
    "\n",
    "Participants and Voting Assignments:\n",
    "{participants_and_assignments_json}\n",
    "\n",
    "Ensure that each participant's voting pattern closely matches their target vote distribution.\n",
    "\n",
    "Return your response in the following JSON format:\n",
    "{{\n",
    "    \"votes\": [\n",
    "        {{\n",
    "            \"participant_id\": \"Unique identifier\",\n",
    "            \"votes\": {{\"statement_id\": vote, ...}}\n",
    "        }},\n",
    "        ...\n",
    "    ]\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "vote_simulation_response = get_openai_completion(vote_simulation_prompt)\n",
    "\n",
    "try:\n",
    "    vote_data = json.loads(vote_simulation_response)\n",
    "    votes = vote_data['votes']\n",
    "    print(\"\\nSimulated Votes:\")\n",
    "    print(json.dumps(vote_data, indent=4))\n",
    "except json.JSONDecodeError as e:\n",
    "    print(f\"Error parsing JSON: {e}\")\n",
    "    votes = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Vote Matrix Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create empty matrix (rows = participants, columns = statements)\n",
    "participant_ids = [vote['participant_id'] for vote in votes]\n",
    "statement_ids = [s['statement_id'] for s in statements_list]\n",
    "\n",
    "vote_matrix = pd.DataFrame(index=participant_ids, columns=statement_ids)\n",
    "\n",
    "# Populate matrix with extracted votes\n",
    "for vote_entry in votes:\n",
    "    participant_id = vote_entry['participant_id']\n",
    "    participant_votes = vote_entry['votes']\n",
    "    for stmt_id, vote_value in participant_votes.items():\n",
    "        vote_matrix.at[participant_id, int(stmt_id)] = vote_value\n",
    "\n",
    "# Convert data types\n",
    "vote_matrix = vote_matrix.apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Results Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate heatmap of Vote Matrix\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.imshow(vote_matrix.fillna(0), aspect='auto', cmap='bwr', interpolation='none')\n",
    "plt.colorbar(label='Vote (-1: Disagree, 0: Pass, 1: Agree)')\n",
    "plt.xlabel('Statements')\n",
    "plt.ylabel('Participants')\n",
    "plt.title('Vote Matrix Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display vote distribution statistics\n",
    "vote_counts = vote_matrix.stack().value_counts()\n",
    "print(\"\\n### Vote Distribution Statistics ###\")\n",
    "print(vote_counts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
